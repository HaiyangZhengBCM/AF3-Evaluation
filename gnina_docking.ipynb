{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script contains functions to conduct gnina docking for our evaluation purposes\n",
    "from pymol import cmd\n",
    "from pdbfixer import PDBFixer\n",
    "from openmm.app import PDBFile\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cif_to_pdb(input_cif, output_pdb):\n",
    "    cmd.delete(\"all\")\n",
    "    \"\"\"\n",
    "    Convert a CIF file to a PDB file using PyMOL.\n",
    "    Ensures ligands and heteroatoms are preserved.\n",
    "    \n",
    "    Parameters:\n",
    "        input_cif (str): Path to the input CIF file.\n",
    "        output_pdb (str): Path to save the output PDB file.\n",
    "    \"\"\"\n",
    "    # Load the CIF file\n",
    "    cmd.load(input_cif, \"structure\")\n",
    "    # Save the structure as PDB\n",
    "    cmd.save(output_pdb, \"structure\")\n",
    "    print(f\"Converted {input_cif} to {output_pdb}\")\n",
    "    # Clean up PyMOL session\n",
    "    cmd.delete(\"all\")\n",
    "\n",
    "\n",
    "def split_non_standard_residues(input_pdb, receptor_pdb, ligand_pdb, ligand_sdf):\n",
    "    cmd.delete(\"all\")\n",
    "    \"\"\"\n",
    "    Splits a protein-ligand complex into receptor and ligand files by identifying non-standard residues.\n",
    "\n",
    "    Parameters:\n",
    "    - input_pdb (str): Path to the input PDB file containing the protein-ligand complex.\n",
    "    - receptor_output (str): Path to save the receptor PDB file.\n",
    "    - ligand_output (str): Path to save the ligand PDB file.\n",
    "    \"\"\"\n",
    "    # List of standard amino acid residue names\n",
    "    standard_residues = [\n",
    "        \"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLN\", \"GLU\", \"GLY\",\n",
    "        \"HIS\", \"ILE\", \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\", \"SER\",\n",
    "        \"THR\", \"TRP\", \"TYR\", \"VAL\"\n",
    "    ]\n",
    "\n",
    "    # Convert the list into a selection-friendly string\n",
    "    standard_residue_selection = \"+\".join(standard_residues)\n",
    "\n",
    "    # Load the PDB file\n",
    "    cmd.load(input_pdb, \"complex\")\n",
    "\n",
    "    # Select the ligand (non-standard residues)\n",
    "    cmd.select(\"ligand\", f\"not resn {standard_residue_selection}\")\n",
    "\n",
    "    # Save the ligand atoms\n",
    "    if cmd.count_atoms(\"ligand\") > 0:\n",
    "        cmd.save(ligand_pdb, \"ligand\")\n",
    "        print(f\"Ligand saved to {ligand_pdb}\")\n",
    "    else:\n",
    "        print(\"No non-standard residues found. Check the input PDB.\")\n",
    "\n",
    "\n",
    "    # Select the receptor\n",
    "    cmd.select(\"receptor\", f\"resn {standard_residue_selection}\")\n",
    "    # Save the ligand atoms\n",
    "    if cmd.count_atoms(\"receptor\") > 0:\n",
    "        cmd.save(receptor_pdb, \"receptor\")\n",
    "        print(f\"Ligand saved to {ligand_pdb}\")\n",
    "    else:\n",
    "        print(\"No standard residues found. Check the input PDB.\")\n",
    "    # Clean up PyMOL objects\n",
    "    cmd.delete(\"all\")\n",
    "    cmd.load(ligand_pdb)\n",
    "    cmd.save(ligand_sdf)\n",
    "    cmd.save(ligand_pdb)\n",
    "    cmd.delete(\"all\")\n",
    "\n",
    "def combine_complex(ligand_pdb, receptor_pdb,output_pdb):\n",
    "    cmd.delete(\"all\")\n",
    "    cmd.load(ligand_pdb)\n",
    "    cmd.load(receptor_pdb)\n",
    "    cmd.save(output_pdb)\n",
    "    cmd.delete(\"all\")\n",
    "\n",
    "def prep_gnina_fix(work_id,minimized_pdb,work_dir):\n",
    "    cmd.delete(\"all\")\n",
    "    fixed_complex_pdb = work_dir+\"/fixed_complex_%s.pdb\"%work_id\n",
    "    fixer = PDBFixer(filename=minimized_pdb)\n",
    "\n",
    "    # Step 2: Identify and fix missing residues\n",
    "    fixer.findMissingResidues()\n",
    "    # By default, PDBFixer may add missing terminal residues. Remove unwanted ones:\n",
    "    chains = list(fixer.topology.chains())\n",
    "    keys = list(fixer.missingResidues.keys())\n",
    "    for key in keys:\n",
    "        chain_id, res_id = key\n",
    "        if res_id == 0 or res_id == len(list(chains[chain_id].residues())):\n",
    "            del fixer.missingResidues[key]\n",
    "\n",
    "    # Step 3: Identify and add missing atoms\n",
    "    fixer.findMissingAtoms()\n",
    "    fixer.addMissingAtoms()\n",
    "\n",
    "    # Step 4: Add missing hydrogens (adjust pH if needed)\n",
    "    fixer.addMissingHydrogens(pH=7.4)\n",
    "\n",
    "    # Step 5: Write the fixed structure to a new PDB file\n",
    "    with open(fixed_complex_pdb, 'w') as output_file:\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, output_file)\n",
    "        \n",
    "    print(\"Fixed PDB file saved as 'fixed_structure.pdb'\")\n",
    "    min_ligand = work_dir + \"/ligand_%s.pdb\"%work_id\n",
    "    min_receptor = work_dir + \"/receptor_%s.pdb\"%work_id\n",
    "    min_ligand_sdf = work_dir + \"/ligand_%s.sdf\"%work_id\n",
    "    min_complex_docking = work_dir + \"/complex_docking%s.pdb\"%work_id\n",
    "    split_non_standard_residues(fixed_complex_pdb, min_receptor,min_ligand, min_ligand_sdf)\n",
    "    cmd.delete(\"all\")\n",
    "    cmd.load(min_ligand)\n",
    "    cmd.save(min_ligand)\n",
    "    cmd.save(min_ligand_sdf)\n",
    "    cmd.delete(\"all\")\n",
    "    combine_complex(min_ligand_sdf,min_receptor,min_complex_docking)\n",
    "    return min_ligand_sdf, min_receptor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract results from GNINA docking\n",
    "def extract_affinity_and_cnn_affinity(gnina_output_path):\n",
    "    affinities = []\n",
    "    cnn_affinities = []\n",
    "\n",
    "    with open(gnina_output_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        parsing = False  # A flag to indicate when we reach the scores section\n",
    "\n",
    "        for line in lines:\n",
    "            # Check for the header line to start parsing\n",
    "            if line.strip().startswith(\"mode |\"):\n",
    "                parsing = True\n",
    "                continue\n",
    "            if parsing and line.strip() == \"\":  # Stop parsing at the end of the table\n",
    "                break\n",
    "            if parsing:\n",
    "                try:\n",
    "                    # Extract the columns of interest\n",
    "                    values = line.split()  # Split by whitespace\n",
    "                    affinity = float(values[1])  # Extract affinity\n",
    "                    cnn_affinity = float(values[-1])  # Extract CNN affinity (last column)\n",
    "                    affinities.append(affinity)\n",
    "                    cnn_affinities.append(cnn_affinity)\n",
    "                except (IndexError, ValueError):\n",
    "                    continue  # Handle malformed lines gracefully\n",
    "\n",
    "    return affinities, cnn_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae518494",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/path/to/your/cif/files\"  # Replace with your directory containing CIF files\n",
    "work_dir = \"/path/to/your/work_dir\"  # Replace with your desired working directory\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(directory):\n",
    "    # Check if the file ends with `_model.cif`\n",
    "    if file_name.endswith(\".cif\"):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        pdb_path = file_path.replace(\".cif\", \".pdb\")\n",
    "        convert_cif_to_pdb(file_path, pdb_path)\n",
    "        job_id = file_name.replace(\".cif\", \"\")\n",
    "        ligand_sdf, receptor = prep_gnina_fix(job_id, pdb_path, work_dir)\n",
    "        gnina_command = \"\"\"\n",
    "        docker run --gpus device=0 -v %s:/scr \n",
    "        gnina/gnina gnina -r /scr/receptor_%s.pdb -l /scr/ligand_%s.sdf --autobox_ligand /scr/ligand_%s.sdf\n",
    "        --cnn_scoring refinement -o /scr/ligand_docked%s.sdf --log /scr/result_%s.log\"\"\"%(work_dir, job_id, job_id, job_id, job_id, job_id)\n",
    "        gnina_command = gnina_command.replace(\"\\n\",\"\")\n",
    "        #print(gnina_command)\n",
    "        os.system(gnina_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f117f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/path/to/your/work_dir\"  # Replace with your directory containing CIF files\n",
    "aff_list = []\n",
    "for file_name in os.listdir(directory):\n",
    "    # Check if the file ends with `_model.cif`\n",
    "    if file_name.endswith(\".log\"):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        job_id = file_name.replace(\"result_\", \"\").replace(\"_model.log\", \"\").upper()\n",
    "        affinties, cnn_affinities = extract_affinity_and_cnn_affinity(file_path)\n",
    "        aff_list.append([job_id,affinties[0],cnn_affinities[0]])\n",
    "aff_df = pd.DataFrame(aff_list,columns = [\"Job ID\", \"predicted affinity\", \"predicted CNN affinity\"])\n",
    "aff_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
